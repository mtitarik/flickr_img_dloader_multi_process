{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mPhrdmWCxH8S",
    "outputId": "b0bac2cb-6d43-49b7-a58f-b1d763b71221"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# gdrive_home_dir = '/content/drive/My Drive/'\n",
    "\n",
    "\n",
    "# !ls '{gdrive_home_dir}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfrwpa0AyLhY"
   },
   "outputs": [],
   "source": [
    "# !pip install flickrapi\n",
    "\n",
    "# import flickrapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI0vkmzIyNge"
   },
   "outputs": [],
   "source": [
    "# Photo Source URL description: https://www.flickr.com/services/api/misc.urls.html\n",
    "\n",
    "# Find the id of a group by group name: https://www.flickr.com/services/api/explore/flickr.urls.lookupGroup\n",
    "# Get photos from a group: https://www.flickr.com/services/api/explore/flickr.groups.pools.getPhotos\n",
    "\n",
    "# flickr photo search api: https://www.flickr.com/services/api/explore/flickr.photos.search\n",
    "\n",
    "# Flickr photo licenses explained: https://www.flickr.com/creativecommons/\n",
    "# Flick photo licenses: https://www.flickr.com/services/api/explore/flickr.photos.licenses.getInfo\n",
    "\n",
    "# sample download scripts: https://gist.github.com/zmwangx/b1c16b197b5416143c7a\n",
    "#                          https://www.programcreek.com/python/example/6468/flickrapi.FlickrAPI\n",
    "#% reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2210
    },
    "colab_type": "code",
    "id": "1g3e7KlMxH8p",
    "outputId": "aea265ff-6bb8-4b02-f53e-3f3e047b35d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total available images: 41411\n",
      "Total available pages: 415\n",
      "More than 4k images in query; segmenting the query\n",
      "image count:  20522  (betweenstart:  2004-12-28 04:03:41Z  end: 2012-02-17 09:24:52Z )\n",
      "Search... image count:  7627  (betweenstart:  2004-12-28 04:03:41Z  end: 2008-07-23 18:44:16Z )\n",
      "Search... image count:  2376  (betweenstart:  2004-12-28 04:03:41Z  end: 2006-10-10 23:23:58Z )\n",
      "Total image count is:  2376\n",
      "\n",
      "image count:  20852  (betweenstart:  2006-10-10 23:23:59Z  end: 2013-01-08 07:05:01Z )\n",
      "Search... image count:  10659  (betweenstart:  2006-10-10 23:23:59Z  end: 2009-11-24 15:14:30Z )\n",
      "Search... image count:  4203  (betweenstart:  2006-10-10 23:23:59Z  end: 2008-05-03 07:19:14Z )\n",
      "Search... image count:  1977  (betweenstart:  2006-10-10 23:23:59Z  end: 2007-07-23 03:21:36Z )\n",
      "Total image count is:  4353\n",
      "\n",
      "image count:  19932  (betweenstart:  2007-07-23 03:21:37Z  end: 2013-05-30 21:03:50Z )\n",
      "Search... image count:  10979  (betweenstart:  2007-07-23 03:21:37Z  end: 2010-06-26 12:12:43Z )\n",
      "Search... image count:  5032  (betweenstart:  2007-07-23 03:21:37Z  end: 2009-01-07 19:47:10Z )\n",
      "Search... image count:  2124  (betweenstart:  2007-07-23 03:21:37Z  end: 2008-04-15 11:34:23Z )\n",
      "Total image count is:  6477\n",
      "\n",
      "image count:  19299  (betweenstart:  2008-04-15 11:34:24Z  end: 2013-10-11 13:10:13Z )\n",
      "Search... image count:  10780  (betweenstart:  2008-04-15 11:34:24Z  end: 2011-01-13 00:22:18Z )\n",
      "Search... image count:  5691  (betweenstart:  2008-04-15 11:34:24Z  end: 2009-08-29 17:58:21Z )\n",
      "Search... image count:  2776  (betweenstart:  2008-04-15 11:34:24Z  end: 2008-12-22 02:46:22Z )\n",
      "Total image count is:  9253\n",
      "\n",
      "image count:  17698  (betweenstart:  2008-12-22 02:46:23Z  end: 2014-02-13 20:46:13Z )\n",
      "Search... image count:  9469  (betweenstart:  2008-12-22 02:46:23Z  end: 2011-07-19 23:46:18Z )\n",
      "Search... image count:  5259  (betweenstart:  2008-12-22 02:46:23Z  end: 2010-04-06 01:16:20Z )\n",
      "Search... image count:  2599  (betweenstart:  2008-12-22 02:46:23Z  end: 2009-08-14 02:01:21Z )\n",
      "Total image count is:  11852\n",
      "\n",
      "image count:  16152  (betweenstart:  2009-08-14 02:01:22Z  end: 2014-06-11 08:23:42Z )\n",
      "Search... image count:  8417  (betweenstart:  2009-08-14 02:01:22Z  end: 2012-01-12 05:12:32Z )\n",
      "Search... image count:  4738  (betweenstart:  2009-08-14 02:01:22Z  end: 2010-10-28 15:36:57Z )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "do_request: Status code 502 received, content:\n",
      "    <!DOCTYPE html>\n",
      "<html lang=\"en-us\"><head>\n",
      "<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
      "    <meta charset=\"utf-8\">\n",
      "    <title>Yahoo</title>\n",
      "    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
      "    <style>\n",
      "html {\n",
      "    height: 100%;\n",
      "}\n",
      "body {\n",
      "    background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\n",
      "    background-size: cover;\n",
      "    height: 100%;\n",
      "    text-align: center;\n",
      "    font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\n",
      "}\n",
      "table {\n",
      "    height: 100%;\n",
      "    width: 100%;\n",
      "    table-layout: fixed;\n",
      "    border-collapse: collapse;\n",
      "    border-spacing: 0;\n",
      "    border: none;\n",
      "}\n",
      "h1 {\n",
      "    font-size: 42px;\n",
      "    font-weight: 400;\n",
      "    color: #400090;\n",
      "}\n",
      "p {\n",
      "    color: #1A1A1A;\n",
      "}\n",
      "#message-1 {\n",
      "    font-weight: bold;\n",
      "    margin: 0;\n",
      "}\n",
      "#message-2 {\n",
      "    display: inline-block;\n",
      "    *display: inline;\n",
      "    zoom: 1;\n",
      "    max-width: 17em;\n",
      "    _width: 17em;\n",
      "}\n",
      "#spanishContent {\n",
      "    display: none;\n",
      "}\n",
      "    </style>\n",
      "<script>\n",
      "  document.write('<img src=\"//geo.yahoo.com/b?s=1197757129\n",
      "    t='+new Date().getTime()+'\n",
      "    err_url='+encodeURIComponent(document.URL)+'\n",
      "    err=502\n",
      "    test='+encodeURIComponent('-')+'\" width=\"0px\" height=\"0px\"/>');\n",
      "</script>\n",
      "</head>\n",
      "<body>\n",
      "<!-- status code : 502 -->\n",
      "<!-- Server Connection Closed -->\n",
      "<!-- host machine: e15.ycpi.nya.yahoo.com -->\n",
      "<!-- timestamp: 1554734792.531 -->\n",
      "<!-- url: https://api.flickr.com/services/rest/-->\n",
      "<table>\n",
      "<tbody><tr>\n",
      "    <td>\n",
      "    <div id=\"englishContent\">\n",
      "        <script type=\"text/javascript\">\n",
      "        if (window.location.hostname=='att.yahoo.com'){\n",
      "            document.write('<img src=\"https://s1.yimg.com/rz/d/att_en-US_f_p_bestfit_2x.png\" alt=\"AT\n",
      "    T\">');\n",
      "        }else{\n",
      "            document.write('<img src=\"https://s.yimg.com/nn/img/yahoo-logo-201402200629.png\" alt=\"Yahoo Logo\">');\n",
      "        }    \n",
      "        </script> \n",
      "        <h1 style=\"margin-top:20px;\">Will be right back...</h1>\n",
      "        <p id=\"message-1\">Thank you for your patience.</p>\n",
      "        <p id=\"message-2\">Our engineers are working quickly to resolve the issue.</p>\n",
      "    </div>\n",
      "    <div id=\"spanishContent\"> \n",
      "        <img src=\"https://s1.yimg.com/rz/d/att_es-US_f_p_bestfit_2x.png\" alt=\"AT\n",
      "    T En Vivo\" style=\"max-width:310px\">\n",
      "        <h1 style=\"margin-top:20px;\">Volvemos enseguidaâ¦</h1>\n",
      "        <p id=\"message-1\">Gracias por tu paciencia.</p>\n",
      "        <p id=\"message-2\">Nuestros ingenieros estÃ¡n trabajando rÃ¡pidamente para resolver el problema.</p>\n",
      "    </div>\n",
      "    <script type=\"text/javascript\">\n",
      "    if (window.location.hostname=='espanol.att.yahoo.com'){\n",
      "        document.getElementById('englishContent').style.display = 'none';\n",
      "        document.getElementById('spanishContent').style.display = 'block';\n",
      "    }   \n",
      "    </script>\n",
      "    </td>\n",
      "</tr>\n",
      "</tbody></table>\n",
      "\n",
      "\n",
      "</body></html>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry attempt:  1\n",
      "Search... image count:  2461  (betweenstart:  2009-08-14 02:01:22Z  end: 2010-03-22 08:49:09Z )\n",
      "Total image count is:  14313\n",
      "\n",
      "[(1104206621, 1160522638), (1160522639, 1185160896), (1185160897, 1208259263), (1208259264, 1229913982), (1229913983, 1250215281), (1250215282, 1269247749)]\n",
      "Downloading page: 1\n",
      "Obtained total 99 image information from 1 pages, total obtained:99\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:199\n",
      "Downloading page: 3\n",
      "Obtained total 99 image information from 3 pages, total obtained:298\n",
      "Downloading page: 4\n",
      "Obtained total 100 image information from 4 pages, total obtained:398\n",
      "Downloading page: 5\n",
      "Obtained total 100 image information from 5 pages, total obtained:498\n",
      "Downloading page: 6\n",
      "Obtained total 100 image information from 6 pages, total obtained:598\n",
      "Downloading page: 7\n",
      "Obtained total 100 image information from 7 pages, total obtained:698\n",
      "Downloading page: 8\n",
      "Obtained total 100 image information from 8 pages, total obtained:798\n",
      "Downloading page: 9\n",
      "Obtained total 100 image information from 9 pages, total obtained:898\n",
      "Downloading page: 10\n",
      "Obtained total 100 image information from 10 pages, total obtained:998\n",
      "Downloading page: 11\n",
      "Obtained total 100 image information from 11 pages, total obtained:1098\n",
      "Downloading page: 12\n",
      "Obtained total 100 image information from 12 pages, total obtained:1198\n",
      "Downloading page: 13\n",
      "Obtained total 99 image information from 13 pages, total obtained:1297\n",
      "Downloading page: 14\n",
      "Obtained total 100 image information from 14 pages, total obtained:1397\n",
      "Downloading page: 15\n",
      "Obtained total 100 image information from 15 pages, total obtained:1497\n",
      "Downloading page: 16\n",
      "Obtained total 100 image information from 16 pages, total obtained:1597\n",
      "Downloading page: 17\n",
      "Obtained total 100 image information from 17 pages, total obtained:1697\n",
      "Downloading page: 18\n",
      "Obtained total 100 image information from 18 pages, total obtained:1797\n",
      "Downloading page: 19\n",
      "Obtained total 100 image information from 19 pages, total obtained:1897\n",
      "Downloading page: 20\n",
      "Obtained total 100 image information from 20 pages, total obtained:1997\n",
      "Downloading page: 21\n",
      "Obtained total 100 image information from 21 pages, total obtained:2097\n",
      "Downloading page: 22\n",
      "Obtained total 100 image information from 22 pages, total obtained:2197\n",
      "Downloading page: 23\n",
      "Obtained total 100 image information from 23 pages, total obtained:2297\n",
      "Downloading page: 24\n",
      "Obtained total 76 image information from 24 pages, total obtained:2373\n",
      "Downloading page: 1\n",
      "Obtained total 100 image information from 1 pages, total obtained:2473\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:2573\n",
      "Downloading page: 3\n",
      "Obtained total 100 image information from 3 pages, total obtained:2673\n",
      "Downloading page: 4\n",
      "Obtained total 100 image information from 4 pages, total obtained:2773\n",
      "Downloading page: 5\n",
      "Obtained total 100 image information from 5 pages, total obtained:2873\n",
      "Downloading page: 6\n",
      "Obtained total 100 image information from 6 pages, total obtained:2973\n",
      "Downloading page: 7\n",
      "Obtained total 100 image information from 7 pages, total obtained:3073\n",
      "Downloading page: 8\n",
      "Obtained total 100 image information from 8 pages, total obtained:3173\n",
      "Downloading page: 9\n",
      "Obtained total 100 image information from 9 pages, total obtained:3273\n",
      "Downloading page: 10\n",
      "Obtained total 100 image information from 10 pages, total obtained:3373\n",
      "Downloading page: 11\n",
      "Obtained total 100 image information from 11 pages, total obtained:3473\n",
      "Downloading page: 12\n",
      "Obtained total 100 image information from 12 pages, total obtained:3573\n",
      "Downloading page: 13\n",
      "Obtained total 100 image information from 13 pages, total obtained:3673\n",
      "Downloading page: 14\n",
      "Obtained total 100 image information from 14 pages, total obtained:3773\n",
      "Downloading page: 15\n",
      "Obtained total 100 image information from 15 pages, total obtained:3873\n",
      "Downloading page: 16\n",
      "Obtained total 100 image information from 16 pages, total obtained:3973\n",
      "Downloading page: 17\n",
      "Obtained total 99 image information from 17 pages, total obtained:4072\n",
      "Downloading page: 18\n",
      "Obtained total 100 image information from 18 pages, total obtained:4172\n",
      "Downloading page: 19\n",
      "Obtained total 100 image information from 19 pages, total obtained:4272\n",
      "Downloading page: 20\n",
      "Obtained total 77 image information from 20 pages, total obtained:4349\n",
      "Downloading page: 1\n",
      "Obtained total 100 image information from 1 pages, total obtained:4449\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:4549\n",
      "Downloading page: 3\n",
      "Obtained total 99 image information from 3 pages, total obtained:4648\n",
      "Downloading page: 4\n",
      "Obtained total 100 image information from 4 pages, total obtained:4748\n",
      "Downloading page: 5\n",
      "Obtained total 100 image information from 5 pages, total obtained:4848\n",
      "Downloading page: 6\n",
      "Obtained total 100 image information from 6 pages, total obtained:4948\n",
      "Downloading page: 7\n",
      "Obtained total 98 image information from 7 pages, total obtained:5046\n",
      "Downloading page: 8\n",
      "Obtained total 100 image information from 8 pages, total obtained:5146\n",
      "Downloading page: 9\n",
      "Obtained total 100 image information from 9 pages, total obtained:5246\n",
      "Downloading page: 10\n",
      "Obtained total 100 image information from 10 pages, total obtained:5346\n",
      "Downloading page: 11\n",
      "Obtained total 100 image information from 11 pages, total obtained:5446\n",
      "Downloading page: 12\n",
      "Obtained total 100 image information from 12 pages, total obtained:5546\n",
      "Downloading page: 13\n",
      "Obtained total 100 image information from 13 pages, total obtained:5646\n",
      "Downloading page: 14\n",
      "Obtained total 100 image information from 14 pages, total obtained:5746\n",
      "Downloading page: 15\n",
      "Obtained total 100 image information from 15 pages, total obtained:5846\n",
      "Downloading page: 16\n",
      "Obtained total 99 image information from 16 pages, total obtained:5945\n",
      "Downloading page: 17\n",
      "Obtained total 99 image information from 17 pages, total obtained:6044\n",
      "Downloading page: 18\n",
      "Obtained total 100 image information from 18 pages, total obtained:6144\n",
      "Downloading page: 19\n",
      "Obtained total 100 image information from 19 pages, total obtained:6244\n",
      "Downloading page: 20\n",
      "Obtained total 100 image information from 20 pages, total obtained:6344\n",
      "Downloading page: 21\n",
      "Obtained total 100 image information from 21 pages, total obtained:6444\n",
      "Downloading page: 22\n",
      "Obtained total 24 image information from 22 pages, total obtained:6468\n",
      "Downloading page: 1\n",
      "Obtained total 100 image information from 1 pages, total obtained:6568\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:6668\n",
      "Downloading page: 3\n",
      "Obtained total 100 image information from 3 pages, total obtained:6768\n",
      "Downloading page: 4\n",
      "Obtained total 100 image information from 4 pages, total obtained:6868\n",
      "Downloading page: 5\n",
      "Obtained total 99 image information from 5 pages, total obtained:6967\n",
      "Downloading page: 6\n",
      "Obtained total 100 image information from 6 pages, total obtained:7067\n",
      "Downloading page: 7\n",
      "Obtained total 100 image information from 7 pages, total obtained:7167\n",
      "Downloading page: 8\n",
      "Obtained total 100 image information from 8 pages, total obtained:7267\n",
      "Downloading page: 9\n",
      "Obtained total 99 image information from 9 pages, total obtained:7366\n",
      "Downloading page: 10\n",
      "Obtained total 100 image information from 10 pages, total obtained:7466\n",
      "Downloading page: 11\n",
      "Obtained total 100 image information from 11 pages, total obtained:7566\n",
      "Downloading page: 12\n",
      "Obtained total 100 image information from 12 pages, total obtained:7666\n",
      "Downloading page: 13\n",
      "Obtained total 100 image information from 13 pages, total obtained:7766\n",
      "Downloading page: 14\n",
      "Obtained total 100 image information from 14 pages, total obtained:7866\n",
      "Downloading page: 15\n",
      "Obtained total 100 image information from 15 pages, total obtained:7966\n",
      "Downloading page: 16\n",
      "Obtained total 100 image information from 16 pages, total obtained:8066\n",
      "Downloading page: 17\n",
      "Obtained total 100 image information from 17 pages, total obtained:8166\n",
      "Downloading page: 18\n",
      "Obtained total 100 image information from 18 pages, total obtained:8266\n",
      "Downloading page: 19\n",
      "Obtained total 100 image information from 19 pages, total obtained:8366\n",
      "Downloading page: 20\n",
      "Obtained total 100 image information from 20 pages, total obtained:8466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading page: 21\n",
      "Obtained total 100 image information from 21 pages, total obtained:8566\n",
      "Downloading page: 22\n",
      "Obtained total 100 image information from 22 pages, total obtained:8666\n",
      "Downloading page: 23\n",
      "Obtained total 100 image information from 23 pages, total obtained:8766\n",
      "Downloading page: 24\n",
      "Obtained total 100 image information from 24 pages, total obtained:8866\n",
      "Downloading page: 25\n",
      "Obtained total 100 image information from 25 pages, total obtained:8966\n",
      "Downloading page: 26\n",
      "Obtained total 100 image information from 26 pages, total obtained:9066\n",
      "Downloading page: 27\n",
      "Obtained total 100 image information from 27 pages, total obtained:9166\n",
      "Downloading page: 28\n",
      "Obtained total 76 image information from 28 pages, total obtained:9242\n",
      "Downloading page: 1\n",
      "Obtained total 98 image information from 1 pages, total obtained:9340\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:9440\n",
      "Downloading page: 3\n",
      "Obtained total 100 image information from 3 pages, total obtained:9540\n",
      "Downloading page: 4\n",
      "Obtained total 100 image information from 4 pages, total obtained:9640\n",
      "Downloading page: 5\n",
      "Obtained total 99 image information from 5 pages, total obtained:9739\n",
      "Downloading page: 6\n",
      "Obtained total 99 image information from 6 pages, total obtained:9838\n",
      "Downloading page: 7\n",
      "Obtained total 100 image information from 7 pages, total obtained:9938\n",
      "Downloading page: 8\n",
      "Obtained total 100 image information from 8 pages, total obtained:10038\n",
      "Downloading page: 9\n",
      "Obtained total 100 image information from 9 pages, total obtained:10138\n",
      "Downloading page: 10\n",
      "Obtained total 100 image information from 10 pages, total obtained:10238\n",
      "Downloading page: 11\n",
      "Obtained total 100 image information from 11 pages, total obtained:10338\n",
      "Downloading page: 12\n",
      "Obtained total 100 image information from 12 pages, total obtained:10438\n",
      "Downloading page: 13\n",
      "Obtained total 100 image information from 13 pages, total obtained:10538\n",
      "Downloading page: 14\n",
      "Obtained total 100 image information from 14 pages, total obtained:10638\n",
      "Downloading page: 15\n",
      "Obtained total 100 image information from 15 pages, total obtained:10738\n",
      "Downloading page: 16\n",
      "Obtained total 100 image information from 16 pages, total obtained:10838\n",
      "Downloading page: 17\n",
      "Obtained total 100 image information from 17 pages, total obtained:10938\n",
      "Downloading page: 18\n",
      "Obtained total 100 image information from 18 pages, total obtained:11038\n",
      "Downloading page: 19\n",
      "Obtained total 100 image information from 19 pages, total obtained:11138\n",
      "Downloading page: 20\n",
      "Obtained total 99 image information from 20 pages, total obtained:11237\n",
      "Downloading page: 21\n",
      "Obtained total 100 image information from 21 pages, total obtained:11337\n",
      "Downloading page: 22\n",
      "Obtained total 100 image information from 22 pages, total obtained:11437\n",
      "Downloading page: 23\n",
      "Obtained total 100 image information from 23 pages, total obtained:11537\n",
      "Downloading page: 24\n",
      "Obtained total 100 image information from 24 pages, total obtained:11637\n",
      "Downloading page: 25\n",
      "Obtained total 100 image information from 25 pages, total obtained:11737\n",
      "Downloading page: 26\n",
      "Obtained total 98 image information from 26 pages, total obtained:11835\n",
      "Downloading page: 1\n",
      "Obtained total 100 image information from 1 pages, total obtained:11935\n",
      "Downloading page: 2\n",
      "Obtained total 100 image information from 2 pages, total obtained:12035\n",
      "Downloading page: 3\n",
      "Obtained total 100 image information from 3 pages, total obtained:12135\n",
      "Attempting to download total 12135 images\n",
      "Number of image downloaders: 61\n",
      "Elapsed time 778.5654802322388 seconds\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "https://stackoverflow.com/questions/1994037/flickr-api-returning-duplicate-photos \n",
    "\n",
    "It is possible to retrieve more than 4000 images from flickr; your query has to be paginated by (for example) temporal range \n",
    "such that the total number of images from that query is not more than 4000. You can also use other parameters such as bounding \n",
    "box to limit the total number of images in the response.\n",
    "\n",
    "For example, if you are searching with the tag 'dogs', this is what you can do ( binary search over time range):\n",
    "\n",
    "Specify a minimum date and a maximum date in the request url, such as Jan 1st, 1990 and Jan 1st 2015.\n",
    "Inspect the total number of images in the response. If it is more than 4000, then divide the temporal range into two and \n",
    "work on the first half until you get less than 4000 images from the query. Once you get that, request all the pages from \n",
    "that time range, and move on to the next interval and do the same until (a) Number of required images is met (b) searched\n",
    "all over the initial time interval.\n",
    "\n",
    "'''\n",
    "\n",
    "#%reload_ext downloader_wrapper\n",
    "\n",
    "from flickr_dloader_utils import *\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Recommended way for creating a multi-process program in python\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    # number of images to download\n",
    "    num_images_to_download = 12000 \n",
    "\n",
    "    # Specify whether to download from a group or by tags\n",
    "    config = 'tags' # possible values: 'group' or 'tags'\n",
    "\n",
    "    # base download directory\n",
    "    #download_dir = f'{gdrive_home_dir}/dataset/test_dataset'\n",
    "    download_dir = f'E:\\\\datasets\\\\tiger_vs_bear\\\\tiger'\n",
    "\n",
    "    # name of the group (if downloading from a group, ignored otherwise)\n",
    "    group_name = 'portrait-gallery'\n",
    "\n",
    "    # tags to be used to searching (if downloading using search tags, ignored otherwise)\n",
    "    tags = 'tiger'\n",
    "\n",
    "    # to try time intervals \n",
    "    SECONDS_IN_A_YEAR = 31536000    \n",
    "    \n",
    "    CURRENT_TIME = int(time.time())\n",
    "    \n",
    "    # maximum number of times to retry if an image info page results in error\n",
    "    MAX_RETRY_COUNT = 3\n",
    "\n",
    "    # maximum number of images to assign to an image downloader process\n",
    "    MAX_LOAD_PER_IMG_DLOADER = 200 \n",
    "    \n",
    "    # maximum number of images information to be contained in a query result page.\n",
    "    # NOTE: Flickr sends the same set of image information if used a number higher than 100.\n",
    "    MAX_IMG_PER_PAGE = 100    \n",
    "    \n",
    "    # hack since api downloads 100 less than the specified number of images\n",
    "    num_images_to_download +=100 \n",
    "    \n",
    "    # finds the number of pages needed to be downloaded\n",
    "    #num_pages = int(math.ceil(num_images_to_download/MAX_IMG_PER_PAGE))\n",
    "\n",
    "    #print(f'Number of pages needed for {num_images_to_download} images: {num_pages}')\n",
    "    \n",
    "    # settings for downloading images from a group or by search keywords/tags\n",
    "    configs = { 'group': {\n",
    "                            'search_criteria' : group_name,\n",
    "                            'download_dir' : download_dir,    \n",
    "                            #'image_info_save_file' : 'query_results_bygroup__' + group_name,\n",
    "                            'url_downloader' : download_flickr_img_by_group, # image info downloader function for groups\n",
    "                        },\n",
    "               'tags': {\n",
    "                            'search_criteria' : tags,\n",
    "                            'download_dir' : download_dir,    \n",
    "                            #'image_info_save_file' : 'query_results_bytags__' + \".\".join(tags.split(\",\")),\n",
    "                            'url_downloader' : download_flickr_img_url_by_tag, # image info downloader function for tags\n",
    "                        }\n",
    "              }\n",
    "\n",
    "    retry_count = 0\n",
    "    is_page_error = True\n",
    "    while retry_count < MAX_RETRY_COUNT and is_page_error:  \n",
    "        try:  \n",
    "            # execute the query for finding out the number of pages available \n",
    "            result = configs[config]['url_downloader'](configs[config]['search_criteria'])\n",
    "            is_page_error = False \n",
    "        except Exception as e:\n",
    "            # enforced delay not to overwhelm the Flickr API  \n",
    "            retry_count += 1\n",
    "            print('Retry attempt: ', retry_count)\n",
    "            time.sleep(2)    \n",
    "    \n",
    "   \n",
    "    # Number of pages in the result    \n",
    "    pagecount = result['photos']['pages']\n",
    "    imgCount = int(result['photos']['total'])\n",
    "    \n",
    "    print(f\"Total available images: {imgCount}\")\n",
    "    print(f'Total available pages: {pagecount}')\n",
    "\n",
    "    results = []\n",
    "    search_time_intervals = []\n",
    "\n",
    "    # split the date range so that each query results in less than total 4000 images; otherwise flickr returns duplicates\n",
    "    if(imgCount > 4000):\n",
    "        print('More than 4k images in query; segmenting the query')\n",
    "        photo_uploaddates = [photo['dateupload'] for photo in result['photos']['photo'] ]\n",
    "        start_upload_date = int(photo_uploaddates[0])\n",
    "        #end_upload_date = start_upload_date + SECONDS_IN_A_YEAR\n",
    "        \n",
    "        #print(first_photo_upload_date)                  \n",
    "        #print(result)\n",
    "        \n",
    "        #unique_query_photos = { photo['id']:photo for result in results for photo in result['photos']['photo']}\n",
    "        #unique_query_photos = {}\n",
    "        total_img_count = 0\n",
    "        \n",
    "        while( total_img_count < num_images_to_download and start_upload_date < CURRENT_TIME ):\n",
    "            interval_length = (CURRENT_TIME - start_upload_date)//2  #10*SECONDS_IN_A_YEAR\n",
    "            end_upload_date = start_upload_date + interval_length\n",
    "            \n",
    "            start_time_h = datetime.datetime.utcfromtimestamp(start_upload_date).strftime('%Y-%m-%d %H:%M:%SZ')\n",
    "            end_time_h = datetime.datetime.utcfromtimestamp(end_upload_date).strftime('%Y-%m-%d %H:%M:%SZ')\n",
    "            \n",
    "            \n",
    "            retry_count = 0\n",
    "            is_page_error = True\n",
    "            while retry_count < MAX_RETRY_COUNT and is_page_error:  \n",
    "                try:  \n",
    "                    # execute the query for finding out the number of pages available \n",
    "                    result = configs[config]['url_downloader'](configs[config]['search_criteria'], pagenum = None, \n",
    "                                                                                           show_log = False, \n",
    "                                start_date = start_upload_date, end_date = end_upload_date)\n",
    "            \n",
    "                    is_page_error = False \n",
    "                except Exception as e:\n",
    "                    # enforced delay not to overwhelm the Flickr API  \n",
    "                    retry_count += 1\n",
    "                    print('Retry attempt: ', retry_count)\n",
    "                    time.sleep(1)    \n",
    "            \n",
    "            time.sleep(0.5)\n",
    "            imgCount = int(result['photos']['total'])\n",
    "            print(\"image count: \", imgCount, \" (between\", end=\"\") \n",
    "            print(\"start: \", start_time_h, \" end:\", end_time_h, \")\" )\n",
    "            \n",
    "            while(imgCount > 4000 and interval_length > 1):\n",
    "                \n",
    "                interval_length //= 2\n",
    "                end_upload_date = start_upload_date + interval_length\n",
    "                \n",
    "                start_time_h = datetime.datetime.utcfromtimestamp(start_upload_date).strftime('%Y-%m-%d %H:%M:%SZ')\n",
    "                end_time_h = datetime.datetime.utcfromtimestamp(end_upload_date).strftime('%Y-%m-%d %H:%M:%SZ')\n",
    "                    \n",
    "                retry_count = 0\n",
    "                is_page_error = True\n",
    "                while retry_count < MAX_RETRY_COUNT and is_page_error:  \n",
    "                    try:  \n",
    "                        # execute the query for finding out the number of pages available \n",
    "                        result = configs[config]['url_downloader'](configs[config]['search_criteria'], pagenum = None, \n",
    "                                                                                               show_log = False, \n",
    "                                    start_date = start_upload_date, end_date = end_upload_date)\n",
    "\n",
    "                        is_page_error = False \n",
    "                    except Exception as e:\n",
    "                        # enforced delay not to overwhelm the Flickr API  \n",
    "                        retry_count += 1\n",
    "                        print('Retry attempt: ', retry_count)\n",
    "                        time.sleep(2)                \n",
    "                \n",
    "                time.sleep(0.5)\n",
    "                imgCount = int(result['photos']['total'])\n",
    "                print(\"Search... image count: \", imgCount, \" (between\", end=\"\") \n",
    "                print(\"start: \", start_time_h, \" end:\", end_time_h, \")\" )\n",
    "            \n",
    "            # found query with less than 4k images, so add the start and end times to the list \n",
    "            search_time_intervals.append( (start_upload_date, end_upload_date ) )\n",
    "            total_img_count += imgCount\n",
    "            \n",
    "            # update start time for the next query\n",
    "            start_upload_date = end_upload_date + 1\n",
    "            \n",
    "            print(\"Total image count is: \", total_img_count)\n",
    "            print()\n",
    "            \n",
    "    else:\n",
    "        results.append(result)\n",
    "\n",
    "        \n",
    "    print(search_time_intervals)\n",
    "    \n",
    "    query_photos = {}\n",
    "            \n",
    "    for start_upload_date, end_upload_date in search_time_intervals:\n",
    "        retry_count = 0\n",
    "        is_page_error = True\n",
    "        while retry_count < MAX_RETRY_COUNT and is_page_error:  \n",
    "            try:  \n",
    "                # execute the query for finding out the number of pages available \n",
    "                # execute the query for finding out the number of pages available \n",
    "                result = configs[config]['url_downloader'](configs[config]['search_criteria'], pagenum = None, \n",
    "                                                                                           show_log = False, \n",
    "                                start_date = start_upload_date, end_date = end_upload_date)\n",
    "                is_page_error = False \n",
    "            except Exception as e:\n",
    "                # enforced delay not to overwhelm the Flickr API  \n",
    "                retry_count += 1\n",
    "                print('Retry attempt: ', retry_count)\n",
    "                time.sleep(2)    \n",
    "\n",
    "\n",
    "            # Number of pages in the result    \n",
    "            pagecount = result['photos']['pages']\n",
    "        \n",
    "            page_idx = 0\n",
    "\n",
    "            \n",
    "            has_stalled = False\n",
    "\n",
    "            image_counts = []  \n",
    "            # download image info (can't be done parallely since can't instantiate more than one Flickr api instances with \n",
    "            # the same api key: possibly can be done by using one key per instance)          \n",
    "            while len(query_photos.items()) < num_images_to_download and page_idx < pagecount and not has_stalled:\n",
    "\n",
    "                page_idx += 1\n",
    "\n",
    "                is_page_error = True\n",
    "                \n",
    "                retry_count = 0\n",
    "\n",
    "                while retry_count < MAX_RETRY_COUNT and is_page_error:  \n",
    "                    try:  \n",
    "                        # download image info as a dictionary and append to a list  \n",
    "                        result = configs[config]['url_downloader'](configs[config]['search_criteria'], page_idx, \n",
    "                                                                           show_log = True, \n",
    "                                start_date = start_upload_date, end_date = end_upload_date)\n",
    "                        \n",
    "                        is_page_error = False \n",
    "                    except Exception as e:\n",
    "                        # enforced delay not to overwhelm the Flickr API  \n",
    "                        retry_count += 1\n",
    "                        print('Retry attempt: ', retry_count)\n",
    "                        time.sleep(2)\n",
    "\n",
    "                results.append(result)\n",
    "                # enforced delay not to overwhelm the Flickr API  \n",
    "                time.sleep(0.5)\n",
    "\n",
    "                # construct a dictionary of returned photos to eliminate ducplicate images (based on image id)      \n",
    "                query_photos_this_page = { photo['id']:photo for photo in result['photos']['photo']}\n",
    "\n",
    "                query_photos.update(query_photos_this_page)\n",
    "\n",
    "                # compute the number of image information obtained       \n",
    "                actual_total_image_count = len(query_photos.items()) # Flickr returns 100 less images for some reason\n",
    "\n",
    "                image_counts.append(actual_total_image_count)\n",
    "\n",
    "                print(f'Obtained total {len(query_photos_this_page.items())} image information from {page_idx} pages, total obtained:{actual_total_image_count}')\n",
    "\n",
    "                if(len(image_counts) > 5 and image_counts[-1] < image_counts[-5] + 20):\n",
    "                    has_stalled = True\n",
    "    \n",
    "    print(f'Attempting to download total {actual_total_image_count} images')          \n",
    "\n",
    "          \n",
    "    ## Download the images from the downloaded image information           \n",
    "          \n",
    "    # update num_process to reflect actual image count\n",
    "    num_processes = int(math.ceil(actual_total_image_count/MAX_LOAD_PER_IMG_DLOADER))\n",
    "              \n",
    "    print(f'Number of image downloaders: {num_processes}')\n",
    "              \n",
    "    # arrange the image downloader arguments for multi-process environment          \n",
    "    args = get_worker_args(num_processes, query_photos, MAX_LOAD_PER_IMG_DLOADER, configs[config]['download_dir'], \n",
    "                            'c', None)\n",
    "    \n",
    "    # for suppressing process output\n",
    "    def mute():\n",
    "        sys.stdout = open(os.devnull, 'w')   \n",
    "              \n",
    "    start = time.time()\n",
    "              \n",
    "    with Pool(num_processes) as p:\n",
    "        p.map(downloader_wrapper, args);\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'Elapsed time {end-start} seconds')\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRiX8-xUxH8x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dist_Flickr_image_downloaders.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
